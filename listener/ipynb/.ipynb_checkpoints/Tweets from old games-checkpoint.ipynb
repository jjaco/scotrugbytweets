{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets from old games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scotrugbytweets` uses some rudimentary NLP-based named entity extraction from `nltk` with some fairly poor results. I've added a 'boring term' blacklist (team names, home nations, sponsors) but this is fairly unscalable and might miss out on some cool organic trends. In this notebook, I'll have a look at historical tweets around a Glasgow Warriors and Edinburgh Rugby game to get some insight into what is typically being tweeted about, and what might be interesting for `scotrugbytweets` visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tweepy import OAuthHandler, Cursor, API\n",
    "import yaml\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#add directory above to path (listener Python namespace)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "with open('../credentials.yaml', 'r') as f:\n",
    "    creds = yaml.load(f)\n",
    "    \n",
    "auth = OAuthHandler(creds['consumer']['key'], creds['consumer']['secret'])\n",
    "auth.set_access_token(creds['access']['key'], creds['access']['secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the week-limit on the Twitter API, we can only grab historical tweets from two Scottish games.\n",
    "\n",
    "* **Glasgow Warriors** (A) v. Benetton Treviso (5/1/19 15:00KO)\n",
    "* **Edinburgh** (H) v. Southern Kings (5/1/19 19:35 KO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_meta = {\n",
    "    'GLA': {'kickoff': pd.to_datetime('2019-01-05 15:00'), \n",
    "            'twitter_punc': ['@GlasgowWarriors'], \n",
    "            'opposition': '@BenettonTreviso'},\n",
    "    'EDI': {'kickoff': pd.to_datetime('2019-01-05 19:35'), \n",
    "            'twitter_punc': ['@EdinburghRugby'], \n",
    "            'opposition': '@SouthernKings'}\n",
    "        }\n",
    "\n",
    "def querify(hashtags):\n",
    "    query = ' OR '.join(hashtags)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from nlp import clean_tweet, extract_entities\n",
    "from itertools import chain\n",
    "\n",
    "# for team in games_meta.keys():\n",
    "#     print(team)\n",
    "#     csv_file = open('tweets_{0}.csv'.format(team), 'w')\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "#     #time definition\n",
    "#     window = '1 day'\n",
    "#     start_time = str(games_meta[team]['kickoff'] - pd.Timedelta(window)).split(' ')[0]\n",
    "#     end_time = str(games_meta[team]['kickoff'] + pd.Timedelta(window)).split(' ')[0]\n",
    "\n",
    "#     api = API(auth, wait_on_rate_limit=True)\n",
    "#     tweets = Cursor(api.search, q=querify(games_meta[team]['twitter_punc']), lang=\"en\",\n",
    "#            since=start_time, until=end_time)\n",
    "\n",
    "#     for tweet in tweets.items():\n",
    "#         cleaned_tweet = clean_tweet(tweet.text)\n",
    "#         csv_writer.writerow([tweet.created_at, cleaned_tweet, extract_entities(cleaned_tweet)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('./tweets_GLA.csv', header=None)\n",
    "tweets_df.columns = ['timestamp', 'tweet', 'entities']\n",
    "\n",
    "tweets_df['entities'] = tweets_df['entities'].apply(lambda row: row[1:-1].split(', '))\n",
    "entities = pd.Series([row[1:-1] for row in list(chain(*tweets_df['entities'].values))])\n",
    "entities = entities[entities != ''] #filter empty results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benetton       41\n",
       "Italian        26\n",
       "Conference     20\n",
       "Treviso        17\n",
       "Hastings       12\n",
       "Sam Johnson    12\n",
       "Europe          8\n",
       "Johnson         8\n",
       "Nairn           7\n",
       "Kick            7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build corpus from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasgow = pd.read_csv('./tweets_GLA.csv', header=None)\n",
    "reekie = pd.read_csv('./tweets_EDI.csv', header=None)\n",
    "\n",
    "combined = pd.concat([glasgow, reekie])\n",
    "combined.columns = ['timestamp', 'tweet', 'entities']\n",
    "combined.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp import extract_feature_vector\n",
    "\n",
    "test_sentence = \"\"\"The best player tonight \n",
    "was Ryan Wilson, who scored twice despite Peter Horne's passing\"\"\"\n",
    "x = extract_feature_vector(test_sentence, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for tweet, index in combined[['tweet', 'index']].values:\n",
    "    corpus.append(extract_feature_vector(tweet, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.concat(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
