{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets from old games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scotrugbytweets` uses some rudimentary NLP-based named entity extraction from `nltk` with some fairly poor results. I've added a 'boring term' blacklist (team names, home nations, sponsors) but this is fairly unscalable and might miss out on some cool organic trends. In this notebook, I'll have a look at historical tweets around a Glasgow Warriors and Edinburgh Rugby game to get some insight into what is typically being tweeted about, and what might be interesting for `scotrugbytweets` visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tweepy import OAuthHandler, Cursor, API\n",
    "import yaml\n",
    "\n",
    "#add directory above to path (listener Python namespace)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "with open('../credentials.yaml', 'r') as f:\n",
    "    creds = yaml.load(f)\n",
    "    \n",
    "auth = OAuthHandler(creds['consumer']['key'], creds['consumer']['secret'])\n",
    "auth.set_access_token(creds['access']['key'], creds['access']['secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the week-limit on the Twitter API, we can only grab historical tweets from two Scottish games.\n",
    "\n",
    "* **Glasgow Warriors** (A) v. Benetton Treviso (5/1/19 15:00KO)\n",
    "* **Edinburgh** (H) v. Southern Kings (5/1/19 19:35 KO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_meta = {\n",
    "    'GLA': {'kickoff': pd.to_datetime('2019-01-05 15:00'), \n",
    "            'twitter_punc': ['@GlasgowWarriors'], \n",
    "            'opposition': '@BenettonTreviso'},\n",
    "    'EDI': {'kickoff': pd.to_datetime('2019-01-05 19:35'), \n",
    "            'twitter_punc': ['@EdinburghRugby'], \n",
    "            'opposition': '@SouthernKings'}\n",
    "        }\n",
    "\n",
    "def querify(hashtags):\n",
    "    query = ' OR '.join(hashtags)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLA\n",
      "EDI\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from nlp import clean_tweet, extract_entities\n",
    "from itertools import chain\n",
    "\n",
    "for team in games_meta.keys():\n",
    "    print(team)\n",
    "    csv_file = open('tweets_{0}.csv'.format(team), 'w')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    #time definition\n",
    "    window = '1 day'\n",
    "    start_time = str(games_meta[team]['kickoff'] - pd.Timedelta(window)).split(' ')[0]\n",
    "    end_time = str(games_meta[team]['kickoff'] + pd.Timedelta(window)).split(' ')[0]\n",
    "\n",
    "    api = API(auth, wait_on_rate_limit=True)\n",
    "    tweets = Cursor(api.search, q=querify(games_meta[team]['twitter_punc']), lang=\"en\",\n",
    "           since=start_time, until=end_time)\n",
    "\n",
    "    for tweet in tweets.items():\n",
    "        cleaned_tweet = clean_tweet(tweet.text)\n",
    "        csv_writer.writerow([tweet.created_at, cleaned_tweet, extract_entities(cleaned_tweet)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('./tweets_GLA.csv', header=None)\n",
    "tweets_df.columns = ['timestamp', 'tweet', 'entities']\n",
    "\n",
    "tweets_df['entities'] = tweets_df['entities'].apply(lambda row: row[1:-1].split(', '))\n",
    "entities = pd.Series([row[1:-1] for row in list(chain(*tweets_df['entities'].values))])\n",
    "entities = entities[entities != ''] #filter empty results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benetton          41\n",
       "Italian           26\n",
       "Conference        20\n",
       "Treviso           17\n",
       "Sam Johnson       12\n",
       "Hastings          12\n",
       "Europe             8\n",
       "Johnson            8\n",
       "Kick               7\n",
       "Rennie             7\n",
       "Horne              7\n",
       "SCRUM              7\n",
       "Nairn              7\n",
       "Dave Rennie        6\n",
       "Dave               6\n",
       "McDowall           5\n",
       "GLA                5\n",
       "Hogg               5\n",
       "Kebble             5\n",
       "Good               5\n",
       "Adam               5\n",
       "Jackson            5\n",
       "Thomson            4\n",
       "Special Win        4\n",
       "Click              4\n",
       "Yep                4\n",
       "Monigo             4\n",
       "Wilson             3\n",
       "Happiness          3\n",
       "Milestone          3\n",
       "                  ..\n",
       "Keep               1\n",
       "America            1\n",
       "Thank              1\n",
       "Mark               1\n",
       "Autumn             1\n",
       "Dylan              1\n",
       "Benetton Rugby     1\n",
       "TRY                1\n",
       "Narin              1\n",
       "Poor               1\n",
       "Dire               1\n",
       "COME               1\n",
       "Charlie            1\n",
       "RUGBY              1\n",
       "Jones              1\n",
       "Dolce Vita         1\n",
       "Unfortunate        1\n",
       "Correct            1\n",
       "LOTR               1\n",
       "New                1\n",
       "Matthew Smith      1\n",
       "Laughable          1\n",
       "Initiative         1\n",
       "Fabulous           1\n",
       "Awful              1\n",
       "SHITE              1\n",
       "American           1\n",
       "Deja               1\n",
       "Genuine            1\n",
       "HAWICK             1\n",
       "Length: 171, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
