{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets from old games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scotrugbytweets` uses some rudimentary NLP-based named entity extraction from `nltk` with some fairly poor results. I've added a 'boring term' blacklist (team names, home nations, sponsors) but this is fairly unscalable and might miss out on some cool organic trends. In this notebook, I'll have a look at historical tweets around a Glasgow Warriors and Edinburgh Rugby game to get some insight into what is typically being tweeted about, and what might be interesting for `scotrugbytweets` visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tweepy import OAuthHandler, Cursor, API\n",
    "import yaml\n",
    "\n",
    "#add directory above to path (listener Python namespace)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "with open('../credentials.yaml', 'r') as f:\n",
    "    creds = yaml.load(f)\n",
    "    \n",
    "auth = OAuthHandler(creds['consumer']['key'], creds['consumer']['secret'])\n",
    "auth.set_access_token(creds['access']['key'], creds['access']['secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the week-limit on the Twitter API, we can only grab historical tweets from two Scottish games.\n",
    "\n",
    "* **Glasgow Warriors** (A) v. Benetton Treviso (5/1/19 15:00KO)\n",
    "* **Edinburgh** (H) v. Southern Kings (5/1/19 19:35 KO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_meta = {\n",
    "    'GLA': {'kickoff': pd.to_datetime('2019-01-05 15:00'), \n",
    "            'twitter_punc': ['@GlasgowWarriors', '#wearewarriors', '#warriornation'], \n",
    "            'opposition': '@BenettonTreviso'},\n",
    "    'EDI': {'kickoff': pd.to_datetime('2019-01-05 19:35'), \n",
    "            'twitter_punc': ['@EdinburghRugby', '#alwaysedinburgh'], \n",
    "            'opposition': '@SouthernKings'}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@GlasgowWarriors', '#wearewarriors', '#warriornation']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_meta['GLA']['twitter_punc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLA\n",
      "EDI\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from nlp import clean_tweet, extract_entities\n",
    "from itertools import chain\n",
    "\n",
    "for team in games_meta.keys():\n",
    "    print(team)\n",
    "    csv_file = open('tweets_{0}.csv'.format(team), 'w')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    #time definition\n",
    "    window = '1 day'\n",
    "    start_time = games_meta[team]['kickoff'] - pd.Timedelta(window)\n",
    "    end_time = games_meta[team]['kickoff'] + pd.Timedelta(window)\n",
    "\n",
    "    api = API(auth)\n",
    "    tweets = Cursor(api.search, q=games_meta[team]['twitter_punc'], lang=\"en\",\n",
    "           since=start_time, until=end_time)\n",
    "\n",
    "    for tweet in tweets.items():\n",
    "        cleaned_tweet = clean_tweet(tweet.text)\n",
    "        print(cleaned_tweet)\n",
    "        csv_writer.writerow([tweet.created_at, cleaned_tweet, extract_entities(cleaned_tweet)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT Just going to leave this here'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 280\r\n",
      "-rw-r--r--  1 jjac  staff   7.9K  8 Jan 18:50 Tweets from old games.ipynb\r\n",
      "-rw-r--r--  1 jjac  staff    81K  8 Jan 18:49 tweets.csv\r\n",
      "-rw-r--r--  1 jjac  staff     0B  8 Jan 19:07 tweets_EDI.csv\r\n",
      "-rw-r--r--  1 jjac  staff     0B  8 Jan 19:07 tweets_GLA.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('./tweets.csv', header=None)\n",
    "tweets_df.columns = ['timestamp', 'tweet', 'entities']\n",
    "\n",
    "tweets_df['entities'] = tweets_df['entities'].apply(lambda row: row[1:-1].split(', '))\n",
    "entities = pd.Series([row[1:-1] for row in list(chain(*tweets_df['entities'].values))])\n",
    "entities = entities[entities != ''] #filter empty results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benetton         43\n",
       "Italian          29\n",
       "Conference       24\n",
       "Treviso          17\n",
       "Hastings         13\n",
       "Sam Johnson      12\n",
       "Rosie            10\n",
       "Horne             8\n",
       "Johnson           8\n",
       "Europe            8\n",
       "Rennie            8\n",
       "SCRUM             7\n",
       "Kick              7\n",
       "Nairn             7\n",
       "Dave Rennie       6\n",
       "Dave              6\n",
       "GLA               5\n",
       "McDowall          5\n",
       "Hogg              5\n",
       "Jackson           5\n",
       "Adam              5\n",
       "Good              5\n",
       "ESPN              5\n",
       "Special Win       5\n",
       "Kebble            5\n",
       "Yep               4\n",
       "Monigo            4\n",
       "Click             4\n",
       "Thomson           4\n",
       "Capitano          4\n",
       "                 ..\n",
       "TRY               1\n",
       "Narin             1\n",
       "Poor              1\n",
       "Dire              1\n",
       "Didn              1\n",
       "LOTR              1\n",
       "GLASGOW           1\n",
       "Strauss           1\n",
       "Total             1\n",
       "Xmas              1\n",
       "Damp              1\n",
       "Matthew Smith     1\n",
       "Hmmm              1\n",
       "Thank             1\n",
       "Update            1\n",
       "Keep              1\n",
       "Possession        1\n",
       "Fantastic         1\n",
       "Irish             1\n",
       "BBC               1\n",
       "Nick Grigg        1\n",
       "Please            1\n",
       "Sweet             1\n",
       "RUGBY             1\n",
       "Jones             1\n",
       "Dolce Vita        1\n",
       "WARRIORS          1\n",
       "Unfortunate       1\n",
       "Correct           1\n",
       "HAWICK            1\n",
       "Length: 192, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
