{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets from old games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scotrugbytweets` uses some rudimentary NLP-based named entity extraction from `nltk` with some fairly poor results. I've added a 'boring term' blacklist (team names, home nations, sponsors) but this is fairly unscalable and might miss out on some cool organic trends. In this notebook, I'll have a look at historical tweets around a Glasgow Warriors and Edinburgh Rugby game to get some insight into what is typically being tweeted about, and what might be interesting for `scotrugbytweets` visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tweepy import OAuthHandler, Cursor, API\n",
    "import yaml\n",
    "\n",
    "#add directory above to path (listener Python namespace)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "with open('../credentials.yaml', 'r') as f:\n",
    "    creds = yaml.load(f)\n",
    "    \n",
    "auth = OAuthHandler(creds['consumer']['key'], creds['consumer']['secret'])\n",
    "auth.set_access_token(creds['access']['key'], creds['access']['secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the week-limit on the Twitter API, we can only grab historical tweets from two Scottish games.\n",
    "\n",
    "* **Glasgow Warriors** (A) v. Benetton Treviso (5/1/19 15:00KO)\n",
    "* **Edinburgh** (H) v. Southern Kings (5/1/19 19:35 KO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_meta = {\n",
    "    'GLA': {'kickoff': pd.to_datetime('2019-01-05 15:00'), \n",
    "            'twitter_punc': ['@GlasgowWarriors'], \n",
    "            'opposition': '@BenettonTreviso'},\n",
    "    'EDI': {'kickoff': pd.to_datetime('2019-01-05 19:35'), \n",
    "            'twitter_punc': ['@EdinburghRugby'], \n",
    "            'opposition': '@SouthernKings'}\n",
    "        }\n",
    "\n",
    "def querify(hashtags):\n",
    "    query = ' OR '.join(hashtags)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLA\n",
      "EDI\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from nlp import clean_tweet, extract_entities\n",
    "from itertools import chain\n",
    "\n",
    "for team in games_meta.keys():\n",
    "    print(team)\n",
    "    csv_file = open('tweets_{0}.csv'.format(team), 'w')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    #time definition\n",
    "    window = '1 day'\n",
    "    start_time = str(games_meta[team]['kickoff'] - pd.Timedelta(window)).split(' ')[0]\n",
    "    end_time = str(games_meta[team]['kickoff'] + pd.Timedelta(window)).split(' ')[0]\n",
    "\n",
    "    api = API(auth, wait_on_rate_limit=True)\n",
    "    tweets = Cursor(api.search, q=querify(games_meta[team]['twitter_punc']), lang=\"en\",\n",
    "           since=start_time, until=end_time)\n",
    "\n",
    "    for tweet in tweets.items():\n",
    "        cleaned_tweet = clean_tweet(tweet.text)\n",
    "        csv_writer.writerow([tweet.created_at, cleaned_tweet, extract_entities(cleaned_tweet)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('./tweets_GLA.csv', header=None)\n",
    "tweets_df.columns = ['timestamp', 'tweet', 'entities']\n",
    "\n",
    "tweets_df['entities'] = tweets_df['entities'].apply(lambda row: row[1:-1].split(', '))\n",
    "entities = pd.Series([row[1:-1] for row in list(chain(*tweets_df['entities'].values))])\n",
    "entities = entities[entities != ''] #filter empty results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BT                       94\n",
       "TRY                      42\n",
       "Great                    27\n",
       "YOUR                     21\n",
       "Big Bill                 20\n",
       "GAME                     18\n",
       "Hickey                   16\n",
       "Fraser McKenzie          13\n",
       "Darcy Graham             11\n",
       "Fraz                     10\n",
       "Try                      10\n",
       "George Taylor            10\n",
       "Darcy                    10\n",
       "Simon                     9\n",
       "Fowles                    9\n",
       "Ross                      8\n",
       "Cammy Fenton              8\n",
       "MOTM                      8\n",
       "Dougie Fife               8\n",
       "Southern Kings            8\n",
       "Ally Miller               8\n",
       "Fife                      7\n",
       "Simon Berghan             7\n",
       "Ally                      7\n",
       "Kings                     7\n",
       "James                     7\n",
       "Rory Sutherland           6\n",
       "Charlie Shiel             6\n",
       "Simon Hickey              6\n",
       "Richard Cockerill         5\n",
       "                         ..\n",
       "Agreed                    1\n",
       "First                     1\n",
       "Charlie Shiels            1\n",
       "Superb                    1\n",
       "Wonder                    1\n",
       "Merve                     1\n",
       "V Southern Kings Come     1\n",
       "Didn                      1\n",
       "Europe                    1\n",
       "Jesus                     1\n",
       "Mission                   1\n",
       "Bright                    1\n",
       "Head Coach                1\n",
       "Key                       1\n",
       "Absolute                  1\n",
       "Murray McCallum           1\n",
       "Nice                      1\n",
       "Fair                      1\n",
       "Treviso                   1\n",
       "HT                        1\n",
       "Nathan Fowles             1\n",
       "Year                      1\n",
       "XXL                       1\n",
       "BLACK                     1\n",
       "Brilliant                 1\n",
       "Yesss                     1\n",
       "Shiel                     1\n",
       "Clinical                  1\n",
       "Pietro Ceccarelli         1\n",
       "List                      1\n",
       "Length: 162, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
